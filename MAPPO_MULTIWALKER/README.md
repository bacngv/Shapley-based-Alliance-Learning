# MAPPO in MULTIWALKER environment

## How to use my code?  
You can dircetly run 'MAPPO_MULTIWALKER_main.py' in your own IDE.<br />

## Trainning environments
- Check out the [PIPELINE](https://colab.research.google.com/drive/1kBkdh8z7fFi_YG96nyfVYGwwGJMd_65Y)
- We train our MAPPO in 'multiwalker' in PettingZoo[sisl] environment.<br />

## Requirements
```
pip install pettingzoo[sisl]
```

## Some details

## Trainning result


## Reference
[1] Yu C, Velu A, Vinitsky E, et al. The Surprising Effectiveness of PPO in Cooperative, Multi-Agent Games[J]. arXiv preprint arXiv:2103.01955, 2021.<br />
[2] [Official implementation of MAPPO](https://github.com/marlbenchmark/on-policy)<br />
[3] [EPyMARL](https://github.com/uoe-agents/epymarl)
